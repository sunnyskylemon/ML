{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ua-hci7EA68n"
      },
      "source": [
        "## Лабораторная работа 2 \"Полносвязные нейронные сети\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hs0_7xDcA68p"
      },
      "source": [
        "ФИО: Иванова Елена Владимировна"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aDezYyEwA68q"
      },
      "source": [
        "В современных фреймворках, нейронные сети конструируются в виде разнообразных слоев. Каждый слой реализует два метода forward и backward. forward предназначен для расчета выхода слоя, backward для расчета градиента. В лабораторной лаботе вам необходимо рализовать оба метода для линейного, сигмоидального и Relu.\n",
        "После чего необходимо сконструировать нейронную сеть для решения задачи классификации."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FOcnRh-fA68r"
      },
      "source": [
        "Функция forward будет вычислять по $x$ значение $y$, backward — по $\\frac{\\partial L}{\\partial y}$ вычислять $\\frac{\\partial L}{\\partial x}$ и обновлять внутри себя $\\frac{\\partial L}{\\partial w}$.\n",
        "\n",
        "Важным требованием к реализации является векторизация всех слоев: все операции должны быть сведены к матричным, не должно быть циклов. Это значительно уменьшает временные затраты."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "kpFL1MBRA68s"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from typing import Tuple\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fs5d527zA68t"
      },
      "source": [
        "### Часть 1: Линейный слой\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gvGaWU5TA68t"
      },
      "source": [
        "Приведем пример вычисления градиентов для линейного слоя: $y = Wx$, $x \\in \\mathbb{R}^{K \\times n}$, $y \\in \\mathbb{R}^{K \\times n}$, $W \\in \\mathbb{R}^{n \\times m}$, где $K$ — число объектов.\n",
        "\n",
        "Рассмотрим $L$ как функцию от выходов нейронной сети: $L = L(y_{11}, y_{12}, \\dots)$\n",
        "\n",
        "$$y_{kt} = (Wx)_{kt} = \\sum_{z=1}^{n} x_{kz}W_{zt}$$\n",
        "\n",
        "$$\\frac{\\partial L}{\\partial x_{ij}} = \\sum_{kt} \\frac{\\partial L}{\\partial y_{kt}}\\frac{\\partial y_{kt}}{\\partial x_{ij}} = \\sum_{kt} \\frac{\\partial L}{\\partial y_{kt}}\\frac{\\partial \\sum_z x_{kz}w_{zt}}{\\partial x_{ij}}= \\sum_{t} \\frac{\\partial L}{\\partial y_{it}}\\frac{\\partial w_{jt}}{\\partial x_{ij}}$$\n",
        "\n",
        "$$\\frac{\\partial{L}}{\\partial x} = \\frac{\\partial{L}}{\\partial y}W^T$$"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Parameters:\n",
        "    def __init__(self, shape: Tuple[int, int]):\n",
        "        \"\"\"\n",
        "        Инициализирует параметры слоя:\n",
        "        - `weights`: случайные веса, инициализированные небольшими значениями.\n",
        "        - `grad`: массив нулей той же формы для хранения градиентов.\n",
        "        \"\"\"\n",
        "        self.weights = np.random.randn(*shape) * 0.1\n",
        "        self.grad = np.zeros_like(self.weights)"
      ],
      "metadata": {
        "id": "_XjH9KZHKUjk"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Linear:\n",
        "    def __init__(self, input_size: int, output_size: int):\n",
        "        \"\"\"\n",
        "        Инициализация линейного слоя.\n",
        "        \"\"\"\n",
        "        self.W = Parameters((output_size, input_size))  # Матрица весов W\n",
        "        self.b = Parameters((output_size, 1))  # Смещения b\n",
        "\n",
        "    def forward(self, X: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Прямой проход (forward propagation):\n",
        "        - X: входной тензор размером (N, input_size).\n",
        "        - Возвращает: выходной тензор размером (N, output_size).\n",
        "        \"\"\"\n",
        "        self.X = X  # Сохраняем вход для использования в backward\n",
        "        return X @ self.W.weights.T + self.b.weights.T  # Вычисляем y = Wx + b\n",
        "\n",
        "    def backward(self, dLdy: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Обратное распространение ошибки (backward propagation):\n",
        "        - dLdy: градиент потерь по y (размер (N, output_size)).\n",
        "        - Вычисляет и сохраняет градиенты dL/dW, dL/db.\n",
        "        - Возвращает градиент dL/dX для предыдущего слоя.\n",
        "        \"\"\"\n",
        "        N = dLdy.shape[0]  # Количество объектов\n",
        "        self.W.grad = (dLdy.T @ self.X) / N  # Градиент по W\n",
        "        self.b.grad = np.sum(dLdy, axis=0, keepdims=True).T / N  # Градиент по b\n",
        "        return dLdy @ self.W.weights  # Градиент по входу X"
      ],
      "metadata": {
        "id": "hT3aHEFKKXIj"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "CIEK1D8mA68t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ffc54117-d5e4-4b1a-b2db-e40956fe3017"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output y:\n",
            " [[ 0.09708512  0.00338722]\n",
            " [ 0.00752138  0.04494277]\n",
            " [ 0.01441669 -0.14908639]\n",
            " [ 0.09461183  0.17893322]\n",
            " [ 0.23821753  0.3036717 ]]\n",
            "Gradient dL/dW:\n",
            " [[ 0.51845998 -0.22215165  0.12091001]\n",
            " [ 0.32376224  0.06265715  0.78233529]]\n",
            "Gradient dL/db:\n",
            " [[ 0.12449137]\n",
            " [-0.58224377]]\n",
            "Gradient dL/dX:\n",
            " [[-0.15368037  0.03244609 -0.0795333 ]\n",
            " [-0.16979008  0.02541724  0.03413334]\n",
            " [-0.07281761  0.0088696   0.0383967 ]\n",
            " [-0.10613055  0.01812225 -0.00480449]\n",
            " [ 0.08994961 -0.02529435  0.12028595]]\n"
          ]
        }
      ],
      "source": [
        "# Тестирование работы слоя\n",
        "if __name__ == \"__main__\":\n",
        "    np.random.seed(42)  # Фиксируем сид для воспроизводимости\n",
        "    layer = Linear(input_size=3, output_size=2)\n",
        "\n",
        "    X = np.random.randn(5, 3)  # 5 объектов, 3 признака\n",
        "    y = layer.forward(X)\n",
        "\n",
        "    dLdy = np.random.randn(5, 2)  # Градиенты потерь\n",
        "    dLdx = layer.backward(dLdy)\n",
        "\n",
        "    print(\"Output y:\\n\", y)\n",
        "    print(\"Gradient dL/dW:\\n\", layer.W.grad)\n",
        "    print(\"Gradient dL/db:\\n\", layer.b.grad)\n",
        "    print(\"Gradient dL/dX:\\n\", dLdx)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Создаем датасет (10 объектов, 2 признака)\n",
        "X_train = torch.randn(10, 2)  # Входные данные (10 объектов, 2 признака)\n",
        "y_train = torch.randint(0, 3, (10,))  # Истинные классы (0, 1 или 2)\n",
        "\n",
        "# Определение нейросети с ReLU\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)  # Первый (скрытый) слой\n",
        "        self.relu = nn.ReLU()  # Функция активации ReLU\n",
        "        self.fc2 = nn.Linear(hidden_size, output_size)  # Выходной слой\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)  # Линейное преобразование fully connected - слой\n",
        "        x = self.relu(x)  # Применяем ReLU\n",
        "        x = self.fc2(x)  # Второе линейное преобразование\n",
        "        return x  # Логиты (без softmax, т.к. CrossEntropyLoss сам его применяет) это тот х,который у\n",
        "\n",
        "# Гиперпараметры\n",
        "input_size = 2      # Количество входных признаков\n",
        "hidden_size = 4     # Количество нейронов в скрытом слое\n",
        "output_size = 3     # Количество классов\n",
        "learning_rate = 0.1 # Скорость обучения\n",
        "num_epochs = 100    # Количество эпох\n",
        "batch_size = 5      # Размер батча\n",
        "\n",
        "# Создаем модель\n",
        "model = NeuralNetwork(input_size, hidden_size, output_size) # количество иксов, скрытый параметр h, игреки\n",
        "\n",
        "# Функция потерь и оптимизатор\n",
        "criterion = nn.CrossEntropyLoss() # используется для многоклассовой классификации\n",
        "optimizer = optim.SGD(model.parameters(), lr=learning_rate) # стохастический градиентный спуск показывает оптимизатору, какие параметры он может вариировать\n",
        "\n",
        "# Обучение с использованием батчей\n",
        "for epoch in range(num_epochs):\n",
        "    for i in range(0, len(X_train), batch_size):\n",
        "        X_batch = X_train[i:i+batch_size]  # Выбираем батч данных\n",
        "        y_batch = y_train[i:i+batch_size]  # Выбираем соответствующие метки\n",
        "\n",
        "        optimizer.zero_grad()  # Обнуляем градиенты\n",
        "\n",
        "        y_pred = model(X_batch)  # Прямой проход\n",
        "        loss = criterion(y_pred, y_batch)  # Вычисляем потерю\n",
        "\n",
        "        loss.backward()  # Обратное распространение ошибки\n",
        "        optimizer.step()  # Обновляем параметры модели\n",
        "\n",
        "    # Выводим потери каждые 10 эпох\n",
        "    if epoch % 10 == 0 or epoch == num_epochs - 1:\n",
        "        print(f\"Эпоха {epoch}, Потеря: {loss.item():.5f}\")\n",
        "\n",
        "# Выводим итоговые веса\n",
        "print(\"\\nИтоговые веса скрытого слоя:\\n\", model.fc1.weight)\n",
        "print(\"\\nИтоговые веса выходного слоя:\\n\", model.fc2.weight)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1NREuAj9NAsN",
        "outputId": "873df2b4-496a-41be-fd0a-a662ffd7b0d7"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Эпоха 0, Потеря: 1.21754\n",
            "Эпоха 10, Потеря: 0.98150\n",
            "Эпоха 20, Потеря: 0.88760\n",
            "Эпоха 30, Потеря: 0.82656\n",
            "Эпоха 40, Потеря: 0.77290\n",
            "Эпоха 50, Потеря: 0.72372\n",
            "Эпоха 60, Потеря: 0.68671\n",
            "Эпоха 70, Потеря: 0.66315\n",
            "Эпоха 80, Потеря: 0.64940\n",
            "Эпоха 90, Потеря: 0.61497\n",
            "Эпоха 99, Потеря: 0.53532\n",
            "\n",
            "Итоговые веса скрытого слоя:\n",
            " Parameter containing:\n",
            "tensor([[ 1.4929, -0.3374],\n",
            "        [ 0.5907, -0.5391],\n",
            "        [-0.0151,  0.3932],\n",
            "        [ 0.9546, -1.2171]], requires_grad=True)\n",
            "\n",
            "Итоговые веса выходного слоя:\n",
            " Parameter containing:\n",
            "tensor([[ 0.6968,  0.0715,  0.4616, -0.2880],\n",
            "        [ 0.8714,  0.1607, -0.2697,  0.9968],\n",
            "        [-1.0239, -0.5231, -0.3855, -0.6204]], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Часть 2, Relu (Rectified Linear Unit - активация нейронов в нейросети)"
      ],
      "metadata": {
        "id": "-ohoXSZLHFpt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Применяем ReLU отдельно\n",
        "with torch.no_grad():  # Отключаем вычисление градиентов\n",
        "    X_test = torch.randn(5, 2)  # Генерируем новые тестовые данные\n",
        "    hidden_output = model.fc1(X_test)  # Выход скрытого слоя (до ReLU)\n",
        "    relu_output = torch.relu(hidden_output)  # Применяем ReLU вручную\n",
        "\n",
        "# Выводим результаты\n",
        "print(\"\\nВыход скрытого слоя (до ReLU):\\n\", hidden_output)\n",
        "print(\"\\nВыход скрытого слоя (после ReLU):\\n\", relu_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p08PeTAkRStN",
        "outputId": "9cd787a9-b593-4987-8ddd-7604c25d5883"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Выход скрытого слоя (до ReLU):\n",
            " tensor([[-0.8062, -2.2979,  0.5624, -4.2132],\n",
            "        [ 1.0239, -0.1742, -0.8008,  0.4118],\n",
            "        [-0.0272, -0.3191, -1.0506,  0.4088],\n",
            "        [ 0.0728, -1.0652, -0.2967, -1.4667],\n",
            "        [ 3.3730,  0.8622, -0.9273,  2.1779]])\n",
            "\n",
            "Выход скрытого слоя (после ReLU):\n",
            " tensor([[0.0000, 0.0000, 0.5624, 0.0000],\n",
            "        [1.0239, 0.0000, 0.0000, 0.4118],\n",
            "        [0.0000, 0.0000, 0.0000, 0.4088],\n",
            "        [0.0728, 0.0000, 0.0000, 0.0000],\n",
            "        [3.3730, 0.8622, 0.0000, 2.1779]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ReLU:\n",
        "    def __init__(self):\n",
        "        self.X = None  # Будем сохранять X для backward\n",
        "\n",
        "    def forward(self, X: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Прямой проход (forward) ReLU: заменяет отрицательные элементы на 0.\n",
        "        \"\"\"\n",
        "        self.X = X  # Сохраняем вход X для backward\n",
        "        return np.maximum(0, X)\n",
        "\n",
        "    def backward(self, dLdy: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Обратное распространение ошибки (backward) через ReLU.\n",
        "        \"\"\"\n",
        "        dLdx = dLdy * (self.X > 0)  # Производная ReLU: 1 для X > 0, иначе 0\n",
        "        return dLdx"
      ],
      "metadata": {
        "id": "qxQS0140NPOP"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Создаем экземпляр ReLU\n",
        "relu = ReLU()\n",
        "\n",
        "# Входные данные\n",
        "X = np.array([[-1.0, 2.0, -3.0], [4.0, -5.0, 6.0]])\n",
        "\n",
        "# Прямой проход через ReLU\n",
        "Y = relu.forward(X)\n",
        "print(\"ReLU Forward:\\n\", Y)\n",
        "\n",
        "# Градиенты от следующего слоя (единичная матрица)\n",
        "dLdy = np.ones_like(X)\n",
        "\n",
        "# Обратное распространение ошибки через ReLU\n",
        "dLdx = relu.backward(dLdy)\n",
        "print(\"ReLU Backward:\\n\", dLdx)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "udcrGsCtS-3F",
        "outputId": "7af7b149-1c5e-4876-f10b-06b6aa59b598"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ReLU Forward:\n",
            " [[0. 2. 0.]\n",
            " [4. 0. 6.]]\n",
            "ReLU Backward:\n",
            " [[0. 1. 0.]\n",
            " [1. 0. 1.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Часть 3, Sigmoid - функция активации нейронной сети\n"
      ],
      "metadata": {
        "id": "wI3xlSHqHJ8_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Sigmoid:\n",
        "    def __init__(self):\n",
        "        self.Y = None  # Будем сохранять выход для backward\n",
        "\n",
        "    def forward(self, X: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Прямой проход (forward): применяет сигмоиду к X.\n",
        "        \"\"\"\n",
        "        self.Y = 1 / (1 + np.exp(-X))  # Формула сигмоиды\n",
        "        return self.Y  # Возвращает преобразованные значения\n",
        "\n",
        "    def backward(self, dLdy: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Обратное распространение (backward):\n",
        "        1. Вычисляет градиент dLdx через производную сигмоиды.\n",
        "        2. Возвращает dLdx.\n",
        "        \"\"\"\n",
        "        dLdx = dLdy * self.Y * (1 - self.Y)  # Производная сигмоиды\n",
        "        return dLdx"
      ],
      "metadata": {
        "id": "rNDhZ8e_UN2F"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Создаем экземпляр сигмоиды\n",
        "sigmoid = Sigmoid()\n",
        "\n",
        "# Входные данные\n",
        "X = np.array([[-1.0, 2.0, -3.0], [4.0, -5.0, 6.0]])\n",
        "\n",
        "# Прямой проход\n",
        "Y = sigmoid.forward(X)\n",
        "print(\"Sigmoid Forward:\\n\", Y)\n",
        "\n",
        "# Градиенты от следующего слоя (единичная матрица)\n",
        "dLdy = np.ones_like(X)\n",
        "\n",
        "# Обратное распространение ошибки\n",
        "dLdx = sigmoid.backward(dLdy)\n",
        "print(\"Sigmoid Backward:\\n\", dLdx)"
      ],
      "metadata": {
        "id": "kXATpUeUHmwo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61cf8a4d-5227-4a38-c32d-3de155c63fcf"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sigmoid Forward:\n",
            " [[0.26894142 0.88079708 0.04742587]\n",
            " [0.98201379 0.00669285 0.99752738]]\n",
            "Sigmoid Backward:\n",
            " [[0.19661193 0.10499359 0.04517666]\n",
            " [0.01766271 0.00664806 0.00246651]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Часть 4, Функция потерь"
      ],
      "metadata": {
        "id": "kELDDVTUHcNW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NLLLoss: # (Negative Log-Likelihood Loss)\n",
        "    def __init__(self):\n",
        "        '''\n",
        "        Применяет Softmax к входу и вычисляет отрицательное логарифмическое правдоподобие (NLL).\n",
        "        '''\n",
        "        self.softmax_output = None  # Будем хранить softmax(X)\n",
        "        self.y = None  # Будем хранить истинные метки\n",
        "\n",
        "    def forward(self, X: np.ndarray, y: np.ndarray) -> float:\n",
        "        \"\"\"\n",
        "        Прямой проход (forward):\n",
        "        - X: (N, C) – входные логиты, где N – число объектов, C – классы.\n",
        "        - y: (N,) – истинные метки классов.\n",
        "\n",
        "        Возвращает **скалярное значение ошибки (среднее по батчу)**.\n",
        "        \"\"\"\n",
        "        # Применяем softmax к X\n",
        "        exp_X = np.exp(X - np.max(X, axis=1, keepdims=True))  # Вычитаем max для числовой стабильности\n",
        "        self.softmax_output = exp_X / np.sum(exp_X, axis=1, keepdims=True)  # Softmax\n",
        "        self.y = y  # Сохраняем метки\n",
        "\n",
        "        # Вычисляем NLL Loss: -log(softmax[class])\n",
        "        N = X.shape[0]  # Число объектов\n",
        "        loss = -np.mean(np.log(self.softmax_output[np.arange(N), y]))  # Среднее по батчу\n",
        "        return loss\n",
        "\n",
        "    def backward(self) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Обратное распространение (backward):\n",
        "        Вычисляет dL/dX (градиент ошибки по входу).\n",
        "        \"\"\"\n",
        "        N = self.softmax_output.shape[0]  # Число объектов\n",
        "        dLdx = self.softmax_output.copy()  # Копируем softmax\n",
        "        dLdx[np.arange(N), self.y] -= 1  # Вычитаем 1 у правильных классов\n",
        "        dLdx /= N  # Усредняем по батчу\n",
        "\n",
        "        return dLdx  # Градиент ошибки по X"
      ],
      "metadata": {
        "id": "sjT4ZTnqHxSa"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Тест\n",
        "# Создаем экземпляр NLLLoss\n",
        "loss_fn = NLLLoss()\n",
        "\n",
        "# Входные логиты (N, C) → 3 объекта, 4 класса\n",
        "X = np.array([[2.0, 1.0, 0.1, -0.5],\n",
        "              [0.2, 2.5, -1.2, 0.3],\n",
        "              [-1.0, 0.8, 3.0, -0.7]])\n",
        "\n",
        "# Истинные классы (0, 1, 2)\n",
        "y = np.array([0, 1, 2])\n",
        "\n",
        "# Вычисляем loss\n",
        "loss_value = loss_fn.forward(X, y)\n",
        "print(\"NLLLoss Forward (Loss):\", loss_value)\n",
        "\n",
        "# Вычисляем градиенты\n",
        "dLdx = loss_fn.backward()\n",
        "print(\"\\nNLLLoss Backward (Gradients):\\n\", dLdx)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q5qDWXLZVNLW",
        "outputId": "f4cd5a04-04d6-43c3-8539-7d855dceeba1"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NLLLoss Forward (Loss): 0.2748386987085118\n",
            "\n",
            "NLLLoss Backward (Gradients):\n",
            " [[-0.12493918  0.07666392  0.03116923  0.01710603]\n",
            " [ 0.02704322 -0.06359937  0.00666877  0.02988738]\n",
            " [ 0.0052912   0.03200991 -0.04444349  0.00714238]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3eMqBrnA68u"
      },
      "source": [
        "### Часть 5, Численный градиент"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6gL63ZVA68u"
      },
      "source": [
        "Релизуйте функцию проверки численного градиента. Для этого для каждой переменной, по которой считается градиент, надо вычислить численный градиент: $f'(x) \\approx \\frac{f(x+\\epsilon)-f(x-\\epsilon)}{2\\epsilon}$. Функция должна возвращать максимальное абсолютное отклонение аналитического градиента от численного. В качестве $\\epsilon$ рекомендуется взять $10^{-6}$. При правильной реализации максимальное отличие будет иметь порядок $10^{-8}-10^{-6}$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "4NMWZB18A68u"
      },
      "outputs": [],
      "source": [
        "eps = 10**(-6)  # Маленькое значение для численного градиента\n",
        "\n",
        "def check_gradient(func, X):\n",
        "    '''\n",
        "    Проверяет корректность вычисления градиента.\n",
        "\n",
        "    func: функция, градиент которой мы проверяем. Должна возвращать (значение функции, аналитический градиент).\n",
        "    X: np.array размера (n x m), по которому вычисляем градиент.\n",
        "\n",
        "    Возвращает: максимальное абсолютное отклонение аналитического градиента от численного.\n",
        "    '''\n",
        "    X = X.astype(float)  # Делаем копию, чтобы избежать ошибок с типами данных\n",
        "    numerical_grad = np.zeros_like(X)  # Численный градиент\n",
        "    f_x, analytical_grad = func(X)  # Вычисляем значение функции и аналитический градиент\n",
        "\n",
        "    # Проходим по каждому элементу X\n",
        "    for i in range(X.shape[0]):\n",
        "        for j in range(X.shape[1]):\n",
        "            X_plus = X.copy()\n",
        "            X_minus = X.copy()\n",
        "\n",
        "            X_plus[i, j] += eps  # Увеличиваем x_ij на epsilon\n",
        "            X_minus[i, j] -= eps  # Уменьшаем x_ij на epsilon\n",
        "\n",
        "            f_x_plus, _ = func(X_plus)  # Вычисляем f(X + eps)\n",
        "            f_x_minus, _ = func(X_minus)  # Вычисляем f(X - eps)\n",
        "\n",
        "            # Численный градиент\n",
        "            numerical_grad[i, j] = (f_x_plus - f_x_minus) / (2 * eps)\n",
        "\n",
        "    # Максимальное отклонение между численным и аналитическим градиентами\n",
        "    max_deviation = np.max(np.abs(numerical_grad - analytical_grad))\n",
        "\n",
        "    return max_deviation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Проверка численного градиента для ReLU\n",
        "# Используем ранее реализованный класс ReLU\n",
        "class ReLU:\n",
        "    def __init__(self):\n",
        "        self.X = None\n",
        "\n",
        "    def forward(self, X):\n",
        "        self.X = X\n",
        "        return np.maximum(0, X)\n",
        "\n",
        "    def backward(self, dLdy):\n",
        "        return dLdy * (self.X > 0)  # Производная ReLU\n",
        "\n",
        "# Функция-обертка для численной проверки градиента\n",
        "def relu_test_function(X):\n",
        "    relu = ReLU()\n",
        "    Y = relu.forward(X)  # Прямой проход\n",
        "    dLdy = np.ones_like(Y)  # Симулируем градиенты от следующего слоя\n",
        "    dLdx = relu.backward(dLdy)  # Обратное распространение\n",
        "    return np.sum(Y), dLdx  # Значение функции и аналитический градиент\n",
        "\n",
        "# Проверяем градиент\n",
        "X_test = np.random.randn(3, 3)  # Случайные данные\n",
        "error = check_gradient(relu_test_function, X_test)\n",
        "print(\"Максимальное отклонение градиента ReLU:\", error)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wf8qom4wVy7S",
        "outputId": "b15239c6-dcac-40da-a37d-a95decc370b7"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Максимальное отклонение градиента ReLU: 8.22666379463044e-11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Проверка численного градиента для Sigmoid\n",
        "# Используем ранее реализованный класс Sigmoid\n",
        "class Sigmoid:\n",
        "    def __init__(self):\n",
        "        self.Y = None\n",
        "\n",
        "    def forward(self, X):\n",
        "        self.Y = 1 / (1 + np.exp(-X))  # Сигмоид\n",
        "        return self.Y\n",
        "\n",
        "    def backward(self, dLdy):\n",
        "        return dLdy * self.Y * (1 - self.Y)  # Производная сигмоиды\n",
        "\n",
        "\n",
        "# Функция-обертка для численной проверки градиента\n",
        "def sigmoid_test_function(X):\n",
        "    sigmoid = Sigmoid()\n",
        "    Y = sigmoid.forward(X)  # Прямой проход\n",
        "    dLdy = np.ones_like(Y)\n",
        "    dLdx = sigmoid.backward(dLdy)  # Обратное распространение\n",
        "    return np.sum(Y), dLdx  # Значение функции и аналитический градиент\n",
        "\n",
        "# Проверяем градиент\n",
        "X_test = np.random.randn(3, 3)  # Случайные данные\n",
        "error = check_gradient(sigmoid_test_function, X_test)\n",
        "print(\"Максимальное отклонение градиента Sigmoid:\", error)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WyBqanenWwfL",
        "outputId": "b5197806-dcab-4db4-93f6-52c707f84708"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Максимальное отклонение градиента Sigmoid: 1.319365727781019e-10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Проверка численного градиента для NLLLoss\n",
        "# Используем ранее реализованный класс NLLLoss\n",
        "class NLLLoss:\n",
        "    def __init__(self):\n",
        "        self.softmax_output = None\n",
        "        self.y = None\n",
        "\n",
        "    def forward(self, X, y):\n",
        "        exp_X = np.exp(X - np.max(X, axis=1, keepdims=True))\n",
        "        self.softmax_output = exp_X / np.sum(exp_X, axis=1, keepdims=True)\n",
        "        self.y = y\n",
        "        return -np.mean(np.log(self.softmax_output[np.arange(X.shape[0]), y]))\n",
        "\n",
        "    def backward(self):\n",
        "        N = self.softmax_output.shape[0]\n",
        "        dLdx = self.softmax_output.copy()\n",
        "        dLdx[np.arange(N), self.y] -= 1\n",
        "        dLdx /= N\n",
        "        return dLdx\n",
        "\n",
        "\n",
        "# Функция-обертка для численной проверки градиента\n",
        "def nllloss_test_function(X):\n",
        "    y_true = np.array([0, 1, 2])  # Пример истинных меток\n",
        "    loss_fn = NLLLoss()\n",
        "    loss = loss_fn.forward(X, y_true)  # Вычисляем loss\n",
        "    dLdx = loss_fn.backward()  # Вычисляем аналитический градиент\n",
        "    return loss, dLdx\n",
        "\n",
        "# Проверяем градиент\n",
        "X_test = np.random.randn(3, 3)  # 3 объекта, 3 класса (логиты)\n",
        "error = check_gradient(nllloss_test_function, X_test)\n",
        "print(\"Максимальное отклонение градиента NLLLoss:\", error)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pjg3OxFWW4kJ",
        "outputId": "92860133-a50c-4759-a599-a95bb1cfa812"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Максимальное отклонение градиента NLLLoss: 1.600208854313223e-10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k3izDY1lA681"
      },
      "source": [
        "### Часть 6, нейронная сеть"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tOYn1yHRA681"
      },
      "source": [
        "Теперь, когда у нас есть \"кирпичики\", мы можем написать класс, который будет собирать всю сеть вместе"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "F5Wam9ZTA681"
      },
      "outputs": [],
      "source": [
        "class NeuralNetwork:\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        \"\"\"\n",
        "        Создает нейросеть:\n",
        "        - Один скрытый слой (Linear + ReLU)\n",
        "        - Выходной слой (Linear)\n",
        "        - Функция потерь: NLLLoss\n",
        "        \"\"\"\n",
        "        self.fc1 = Linear(input_size, hidden_size)\n",
        "        self.relu = ReLU()\n",
        "        self.fc2 = Linear(hidden_size, output_size)\n",
        "        self.loss_fn = NLLLoss()\n",
        "\n",
        "    def forward(self, X, y=None):\n",
        "        \"\"\"\n",
        "        Прямой проход через сеть.\n",
        "        Возвращает:\n",
        "        - log_probs (если y=None)\n",
        "        - loss (если y передан)\n",
        "        \"\"\"\n",
        "        self.hidden_output = self.fc1.forward(X)\n",
        "        self.activated_hidden = self.relu.forward(self.hidden_output)\n",
        "        logits = self.fc2.forward(self.activated_hidden)\n",
        "\n",
        "        # Применяем log_softmax обязательно!\n",
        "        self.log_probs = log_softmax(logits)\n",
        "\n",
        "        if y is None:\n",
        "            return self.log_probs\n",
        "        else:\n",
        "            return self.loss_fn.forward(self.log_probs, y)\n",
        "\n",
        "    def backward(self):\n",
        "        \"\"\"\n",
        "        Обратное распространение ошибки.\n",
        "        \"\"\"\n",
        "        dLdy = self.loss_fn.backward()               # Градиенты от функции потерь ∂L/∂log_probs → (N, C)\n",
        "        dLdx2 = self.fc2.backward(dLdy)              # Градиент по скрытому слою ∂L/∂a2\n",
        "        dLdx1 = self.relu.backward(dLdx2)            # Градиент через ReLU ∂L/∂h1"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Часть 7, Оптимизатор\n",
        "\n",
        "В данном пунте необходимо реализовать оптимизатор, похожий по функционалу на тот, которые используется во фреймворке pytorch. Он состоит из трех методов (включая __init__) __init__ инициализирует параметры, step - обновляет веса, zero_grad - обнуляет градиенты."
      ],
      "metadata": {
        "id": "So2-ij1TIKu4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List\n",
        "\n",
        "class Optimizer:\n",
        "    def __init__(self, parameters: List[\"Parameters\"], lr: float):\n",
        "        \"\"\"\n",
        "        Инициализирует оптимизатор.\n",
        "        parameters: список параметров (весов) модели.\n",
        "        lr: скорость обучения (learning rate).\n",
        "        \"\"\"\n",
        "        self.parameters = parameters  # Список параметров модели\n",
        "        self.lr = lr  # Скорость обучения\n",
        "\n",
        "    def step(self) -> None:\n",
        "        \"\"\"\n",
        "        Обновляет параметры с использованием градиентного спуска:\n",
        "        W = W - lr * grad\n",
        "        \"\"\"\n",
        "        for param in self.parameters:\n",
        "            param.weights -= self.lr * param.grad  # Обновление весов\n",
        "\n",
        "    def zero_grad(self) -> None:\n",
        "        \"\"\"\n",
        "        Обнуляет градиенты перед следующим шагом обучения.\n",
        "        \"\"\"\n",
        "        for param in self.parameters:\n",
        "            param.grad.fill(0)  # Обнуляем градиент"
      ],
      "metadata": {
        "id": "v9iVJgy0IJ2R"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cbOqs9hEA682"
      },
      "source": [
        "### Часть 8, обучение на простых данных"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VLVj0ntMA682"
      },
      "source": [
        "Обучите архитектуру вида 4 -> 100 -> 100 -> 3:\n",
        "* Linear(4, 100)\n",
        "* Relu()\n",
        "* Linear(100, 100)\n",
        "* Relu()\n",
        "* Linear(100, 3)\n",
        "\n",
        "* В качестве функции потерь используйте NLLLoss.\n",
        "\n",
        "* Для обноваления весов используйте написанный вами оптимизатор.\n",
        "* Нарисуйте график сходимости (величина NLL после каждого обновления).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "metadata": {
        "id": "YDhLXycMNWCK"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Загружаем датасет\n",
        "iris = load_iris(as_frame=True)\n",
        "\n",
        "# Создаем DataFrame\n",
        "df = pd.DataFrame(iris[\"data\"], columns=iris[\"feature_names\"])\n",
        "df[\"target\"] = iris[\"target\"]  # Добавляем столбец с метками классов\n",
        "\n",
        "# Выводим таблицу\n",
        "print(df.head(10))  # Вывод первых 5 строк"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fe0S4QqqY1i6",
        "outputId": "4447d10b-5d5f-4af9-e3f9-a4046b8355dd"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
            "0                5.1               3.5                1.4               0.2   \n",
            "1                4.9               3.0                1.4               0.2   \n",
            "2                4.7               3.2                1.3               0.2   \n",
            "3                4.6               3.1                1.5               0.2   \n",
            "4                5.0               3.6                1.4               0.2   \n",
            "5                5.4               3.9                1.7               0.4   \n",
            "6                4.6               3.4                1.4               0.3   \n",
            "7                5.0               3.4                1.5               0.2   \n",
            "8                4.4               2.9                1.4               0.2   \n",
            "9                4.9               3.1                1.5               0.1   \n",
            "\n",
            "   target  \n",
            "0       0  \n",
            "1       0  \n",
            "2       0  \n",
            "3       0  \n",
            "4       0  \n",
            "5       0  \n",
            "6       0  \n",
            "7       0  \n",
            "8       0  \n",
            "9       0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Предобработка\n",
        "X = iris[\"data\"].values\n",
        "y = iris[\"target\"].values\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)"
      ],
      "metadata": {
        "id": "Oq1nfIOlaizd"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Сначала стратифицированное разбиение (с random_state)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y,\n",
        "    stratify=y,\n",
        "    test_size=0.2,\n",
        "    random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "oyHcWVFYN0po"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def log_softmax(x):\n",
        "    x_shifted = x - np.max(x, axis=1, keepdims=True)\n",
        "    exp_x = np.exp(x_shifted)\n",
        "    softmax = exp_x / np.sum(exp_x, axis=1, keepdims=True)\n",
        "    return np.log(softmax + 1e-9)"
      ],
      "metadata": {
        "id": "AQ7Fk4GgQwJU"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DeepNeuralNetwork:\n",
        "    def __init__(self):\n",
        "        self.fc1 = Linear(4, 100)\n",
        "        self.relu1 = ReLU()\n",
        "        self.fc2 = Linear(100, 100)\n",
        "        self.relu2 = ReLU()\n",
        "        self.fc3 = Linear(100, 3)\n",
        "        self.loss_fn = NLLLoss()\n",
        "\n",
        "    def forward(self, X, y=None):\n",
        "        self.h1 = self.relu1.forward(self.fc1.forward(X))\n",
        "        self.h2 = self.relu2.forward(self.fc2.forward(self.h1))\n",
        "        logits = self.fc3.forward(self.h2)\n",
        "        self.out = log_softmax(logits)\n",
        "        if y is None:\n",
        "            return self.out\n",
        "        else:\n",
        "            return self.loss_fn.forward(self.out, y)\n",
        "\n",
        "    def backward(self):\n",
        "        dLdy = self.loss_fn.backward()\n",
        "        print(\"dLdy max:\", np.max(dLdy))  # Отладка: должен быть > 0\n",
        "\n",
        "        dLdx3 = self.fc3.backward(dLdy)\n",
        "        print(\"fc3.W.grad max:\", np.max(self.fc3.W.grad))\n",
        "\n",
        "        dLdx2 = self.relu2.backward(dLdx3)\n",
        "        dLdx1 = self.fc2.backward(dLdx2)\n",
        "        print(\"fc2.W.grad max:\", np.max(self.fc2.W.grad))\n",
        "\n",
        "        dLdx0 = self.relu1.backward(dLdx1)\n",
        "        _ = self.fc1.backward(dLdx0)\n",
        "        print(\"fc1.W.grad max:\", np.max(self.fc1.W.grad))\n",
        "\n",
        "    def parameters(self) -> List[Parameters]:\n",
        "        params = []\n",
        "        for layer in [self.fc1, self.fc2, self.fc3]:\n",
        "            if isinstance(layer, Linear):\n",
        "                params.append(layer.W)\n",
        "                params.append(layer.b)\n",
        "        return params"
      ],
      "metadata": {
        "id": "e75aCqbSOD_w"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Инициализация модели, её параметров и оптимизатора\n",
        "input_size = X_train.shape[1]\n",
        "hidden_size = 100\n",
        "output_size = np.unique(y_train).shape[0]\n",
        "\n",
        "model = DeepNeuralNetwork()\n",
        "criterion = NLLLoss()\n",
        "optimizer = Optimizer(model.parameters(), lr=0.1)"
      ],
      "metadata": {
        "id": "GDTQnPEsOCm0"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 2500\n",
        "batch_size = 64\n",
        "\n",
        "loss_history = []\n",
        "num_samples = X_train.shape[0]\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    indices = np.random.permutation(num_samples)\n",
        "    epoch_loss = 0\n",
        "    num_batches = 0\n",
        "\n",
        "    for start in range(0, num_samples, batch_size):\n",
        "        optimizer.zero_grad()  # Обнуляем градиенты всех параметров\n",
        "\n",
        "        batch_indices = indices[start:start + batch_size]\n",
        "        X_batch = X_train[batch_indices]\n",
        "        y_batch = y_train[batch_indices]\n",
        "\n",
        "        # Прямой проход\n",
        "        logits = model.forward(X_batch)\n",
        "\n",
        "        # Вычисление функции потерь\n",
        "        loss = criterion.forward(logits, y_batch)\n",
        "        epoch_loss += loss\n",
        "        num_batches += 1\n",
        "\n",
        "        # Обратное распространение fcX возвращает градиент по входу, который идёт дальше по цепочке\n",
        "        dLdz = criterion.backward()            # ∂L/∂z (logits)\n",
        "        dh2 = model.fc3.backward(dLdz)         # ∂L/∂h2\n",
        "        da2 = model.relu2.backward(dh2)        # ∂L/∂a2\n",
        "        dh1 = model.fc2.backward(da2)          # ∂L/∂h1\n",
        "        da1 = model.relu1.backward(dh1)        # ∂L/∂a1\n",
        "        _    = model.fc1.backward(da1)         # ∂L/∂x\n",
        "\n",
        "        # Шаг оптимизатора\n",
        "        optimizer.step()\n",
        "\n",
        "    # Логгирование\n",
        "    if epoch % 10 == 0:\n",
        "        avg_epoch_loss = epoch_loss / num_batches\n",
        "        loss_history.append(avg_epoch_loss)\n",
        "\n",
        "    if epoch % 100 == 0:\n",
        "        print(f\"Epoch {epoch}, Avg Loss: {avg_epoch_loss:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JUH1zXu4OOhk",
        "outputId": "3957295a-b342-4b42-eb81-ca88b5476251"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Avg Loss: 1.1496\n",
            "Epoch 100, Avg Loss: 1.0111\n",
            "Epoch 200, Avg Loss: 0.8891\n",
            "Epoch 300, Avg Loss: 0.7723\n",
            "Epoch 400, Avg Loss: 0.6752\n",
            "Epoch 500, Avg Loss: 0.5890\n",
            "Epoch 600, Avg Loss: 0.5195\n",
            "Epoch 700, Avg Loss: 0.4667\n",
            "Epoch 800, Avg Loss: 0.4206\n",
            "Epoch 900, Avg Loss: 0.3914\n",
            "Epoch 1000, Avg Loss: 0.3543\n",
            "Epoch 1100, Avg Loss: 0.3330\n",
            "Epoch 1200, Avg Loss: 0.3082\n",
            "Epoch 1300, Avg Loss: 0.2932\n",
            "Epoch 1400, Avg Loss: 0.2721\n",
            "Epoch 1500, Avg Loss: 0.2549\n",
            "Epoch 1600, Avg Loss: 0.2433\n",
            "Epoch 1700, Avg Loss: 0.2335\n",
            "Epoch 1800, Avg Loss: 0.2192\n",
            "Epoch 1900, Avg Loss: 0.2089\n",
            "Epoch 2000, Avg Loss: 0.2018\n",
            "Epoch 2100, Avg Loss: 0.1918\n",
            "Epoch 2200, Avg Loss: 0.1794\n",
            "Epoch 2300, Avg Loss: 0.1729\n",
            "Epoch 2400, Avg Loss: 0.1663\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(range(0, num_epochs, 10), loss_history, label='Training loss')\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"График функции потерь\")\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        },
        "id": "BI3rPwd8UIt-",
        "outputId": "b2188d9a-e969-45e4-ab01-2e894792e9f1"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "iris[\"target\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "AVI7bN7mOhnJ",
        "outputId": "9c59e8e5-56f0-45b3-811b-037db796f859"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      0\n",
              "1      0\n",
              "2      0\n",
              "3      0\n",
              "4      0\n",
              "      ..\n",
              "145    2\n",
              "146    2\n",
              "147    2\n",
              "148    2\n",
              "149    2\n",
              "Name: target, Length: 150, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>150 rows × 1 columns</p>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}