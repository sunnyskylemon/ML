{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3faecc32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb514c9e",
   "metadata": {},
   "source": [
    "#### Загрузка даных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b02451e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                 haha you guys are a bunch of losers.\n",
       "1    Yet call out all Muslims for the acts of a few...\n",
       "2    This bitch is nuts. Who would read a book by a...\n",
       "3                                     You're an idiot.\n",
       "4    Who cares!? Stark trek and Star Wars fans are ...\n",
       "Name: comment_text, dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# воспроиводимость результатов\n",
    "np.random.seed(0)\n",
    "\n",
    "\n",
    "# Загрузка данных\n",
    "data = pd.read_csv(r\"C:\\Users\\Elena\\Documents\\2025\\МИФИ 2 сем\\Skillfactory\\Этика ИИ\\data.csv\")\n",
    "df = data[\"comment_text\"]\n",
    "target = (data[\"target\"]>0.7).astype(int)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a07953e",
   "metadata": {},
   "source": [
    "#### Исследование и обработка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74b5f1de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 90902 entries, 0 to 90901\n",
      "Series name: comment_text\n",
      "Non-Null Count  Dtype \n",
      "--------------  ----- \n",
      "90902 non-null  object\n",
      "dtypes: object(1)\n",
      "memory usage: 710.3+ KB\n"
     ]
    }
   ],
   "source": [
    "# Информация о df\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b3fbd5",
   "metadata": {},
   "source": [
    "В датасете нет пропусков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe98d631",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 90902 entries, 0 to 90901\n",
      "Series name: target\n",
      "Non-Null Count  Dtype\n",
      "--------------  -----\n",
      "90902 non-null  int32\n",
      "dtypes: int32(1)\n",
      "memory usage: 355.2 KB\n"
     ]
    }
   ],
   "source": [
    "target.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f517c4f",
   "metadata": {},
   "source": [
    "В датасете нет пропусков"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a7974b",
   "metadata": {},
   "source": [
    "### Задание 1 Теперь разделим наши данные на train и test. Пусть в тест у нас пойдет 30% данных. Для этого можете использовать библиотеку train_test_split из sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "965f08d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Тренировочные признаки: 12294                                    Muslim terrorist.\n",
      "57506    It's ironic that these are the same groups tha...\n",
      "56118    Star Wars has a wow factor that Star Trek does...\n",
      "28624    The settlement is 100% appropriate.\\nEnding th...\n",
      "63482    Where did it say to cover your cough with your...\n",
      "                               ...                        \n",
      "6265     You fit perfectly in Clinton's libdem basket o...\n",
      "54886    I'll bet those independent contractors have no...\n",
      "76820    \"Lower tier\" people, especially the young, wer...\n",
      "860      The Devil made her do it and the man too becau...\n",
      "15795    A leak in an 8\" pipe, while obviously not a go...\n",
      "Name: comment_text, Length: 63631, dtype: object\n",
      "---------------------------------------\n",
      "Тренировочные метки: 12294    1\n",
      "57506    0\n",
      "56118    0\n",
      "28624    1\n",
      "63482    0\n",
      "        ..\n",
      "6265     1\n",
      "54886    0\n",
      "76820    0\n",
      "860      1\n",
      "15795    1\n",
      "Name: target, Length: 63631, dtype: int32\n",
      "---------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Разделение данных на тренировочную и тестовую выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df, target,           # данные\n",
    "    test_size=0.3,  # 30% — тестовая выборка\n",
    "    random_state=42 # фиксируем случайность для повторяемости\n",
    ")\n",
    "\n",
    "# Выводим результат\n",
    "print(\"Тренировочные признаки:\", X_train)\n",
    "print(\"---------------------------------------\")\n",
    "print(\"Тренировочные метки:\", y_train)\n",
    "print(\"---------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "66eb8eff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "Тестовые признаки: 80470    Not meaning to belittle your practical concern...\n",
      "28773    Did you mean to imply that the bears are dying...\n",
      "76685    As a 9-year dispatch veteran, let me break it ...\n",
      "12580    A your wimp is traveling across Canada instead...\n",
      "16111    Oh Dispatch, you right wing media elitist rag....\n",
      "                               ...                        \n",
      "27748    The problem with Trump's misogyny is that when...\n",
      "86400                                                 Why?\n",
      "40444    Bull crap!!! ask the Venezuelan's if their \\n\"...\n",
      "53979    Well if you read and understood my posts, you ...\n",
      "13216    you guys really still think that after 40 year...\n",
      "Name: comment_text, Length: 27271, dtype: object\n",
      "---------------------------------------\n",
      "Тестовые метки: 80470    0\n",
      "28773    1\n",
      "76685    0\n",
      "12580    1\n",
      "16111    1\n",
      "        ..\n",
      "27748    1\n",
      "86400    0\n",
      "40444    1\n",
      "53979    0\n",
      "13216    1\n",
      "Name: target, Length: 27271, dtype: int32\n"
     ]
    }
   ],
   "source": [
    "print(\"---------------------------------------\")\n",
    "print(\"Тестовые признаки:\", X_test)\n",
    "print(\"---------------------------------------\")\n",
    "print(\"Тестовые метки:\", y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71ddf18",
   "metadata": {},
   "source": [
    "### Задание 2 Преобразуйте текст, который вы поделили на train и test, в числовой формат с помощью функции CountVectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a6216d2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размерноть датасета X_train_vec (63631, 500)\n",
      "Размерность датасета y_train (63631,)\n",
      "------------------------------------------------------\n",
      "Размерноть датасета X_train_vec (27271, 500)\n",
      "Размерность датасета y_train (27271,)\n"
     ]
    }
   ],
   "source": [
    "# Инициализация векторизатора\n",
    "vectorizer = CountVectorizer(max_features=500)\n",
    "\n",
    "# Преобразование датафрема X_train в новый датафрейм, в котором текст заменены на вектора  \n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "\n",
    "# Преобразование датафрема X_train в новый датафрейм, в котором текст заменены на вектора  \n",
    "X_test_vec = vectorizer.fit_transform(X_test)\n",
    "\n",
    "## Сверяем размерность полученных датасетов \n",
    "print(f'Размерноть датасета X_train_vec', X_train_vec.shape)\n",
    "print(f'Размерность датасета y_train', y_train.shape)\n",
    "\n",
    "print('------------------------------------------------------')\n",
    "print(f'Размерноть датасета X_train_vec', X_test_vec.shape)\n",
    "print(f'Размерность датасета y_train', y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a8e96c",
   "metadata": {},
   "source": [
    "#### Задание 3 Теперь в качестве модели, которая будет классифицировать нам комментарии на токсичные и нетоксичные, возьмем логистическую регрессию. Импортируйте из библиотеки sklearn логистическую регрессию LogisticRegression с параметром max_iter=2000. Для оценки модели возьмите метрику accuracy и посчитайте ее"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975147a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшее значение C: {'C': 5.0}\n",
      "Лучшая точность по CV: 0.8028161576498434\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# param_grid = {\n",
    "#     'C': [0.01, 0.1, 0.5, 1.0, 2.0, 5.0]\n",
    "# }\n",
    "\n",
    "# grid = GridSearchCV(LogisticRegression(max_iter=2000, solver='liblinear'), param_grid, cv=5)\n",
    "# grid.fit(X_train_vec, y_train)\n",
    "\n",
    "# print(\"Лучшее значение C:\", grid.best_params_)\n",
    "# print(\"Лучшая точность по CV:\", grid.best_score_)\n",
    "\n",
    "# # Используем лучшую модель\n",
    "# best_model = grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b3bd437d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Средняя точность по CV: 0.8027532929857994\n",
      "Test Accuracy: 0.6278097612848814\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Инициализация и обучение модели логистической регрессии\n",
    "model = LogisticRegression(\n",
    "    C=3.0,               # можно попробовать 0.1, 0.5, 1, 2, 5\n",
    "    max_iter=2000,\n",
    "    penalty='l2',        # или 'elasticnet' с solver='saga'\n",
    "    solver='liblinear',  # хорошо работает на малых выборках\n",
    "    warm_start=True\n",
    ")\n",
    "# Кросс-валидация\n",
    "scores = cross_val_score(model, X_train_vec, y_train, cv=5)\n",
    "print(\"Средняя точность по CV:\", scores.mean())\n",
    "\n",
    "# Финальное обучение на всех train-данных\n",
    "model.fit(X_train_vec, y_train)\n",
    "\n",
    "# Предсказание на тесте\n",
    "y_pred = model.predict(X_test_vec)\n",
    "print(\"Test Accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79161c11",
   "metadata": {},
   "source": [
    "Получена метрика Accuracy - 62,8% для тестовой выборки, что не очень хорошо (недостаточно), вероятно следует использовать другую модель."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a0bb607",
   "metadata": {},
   "source": [
    "### Задание 4 Чтобы мы смогли протестировать разные комментарии, которые приходят в голову, пропишите ниже функцию, для которой на вход мы бы подавали наш комментарий, а на выход получали предсказание, насколько от 0 до 1 комментарий является токсичным."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5593363a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Нормальное высказывание (вероятность: 0.26)\n",
      "None\n",
      "Токсичное высказывание (вероятность: 1.00)\n",
      "None\n",
      "Нормальное высказывание (вероятность: 0.35)\n",
      "None\n",
      "Нормальное высказывание (вероятность: 0.41)\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def check_toxic(text):\n",
    "    # Векторизация текста\n",
    "    vec = vectorizer.transform([text])\n",
    "    \n",
    "    # Получение вероятности (второй столбец — вероятность класса \"1\")\n",
    "    prob = model.predict_proba(vec)[0][1]\n",
    "    \n",
    "    # Интерпретация\n",
    "    if prob >= 0.5:\n",
    "        print(f\"Токсичное высказывание (вероятность: {prob:.2f})\")\n",
    "    else:\n",
    "        print(f\"Нормальное высказывание (вероятность: {prob:.2f})\")\n",
    "        \n",
    "print(check_toxic(\"you guys really still think that after 40 year\"))\n",
    "print(check_toxic(\"You are stupid\"))\n",
    "print(check_toxic(\"You don't understand simple things\"))\n",
    "print(check_toxic(\"I love apples\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6430f47c",
   "metadata": {},
   "source": [
    "Модель корректно класифицирует высказывания "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f849d5",
   "metadata": {},
   "source": [
    "#### Задание 6 Если ваш алгоритм работает корректно, то комментарий «I love apples» должен быть определен как нетоксичный, а «Apples are stupid» — как токсичный. \n",
    "\n",
    "#### А теперь перейдем к пониманию того, как модель принимает решения: модель присваивает каждому из примерно 58 000 слов коэффициент, причем более высокие коэффициенты обозначают слова, которые модель считает более токсичными. \n",
    "\n",
    "#### Выведите десять слов, которые считаются наиболее токсичными, а также их коэффициенты.\n",
    "#### Hint: в этом вам поможет атрибут vectorizer.vocabulary_.keys() и classifier.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9c674955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 самых «токсичных» слов и их коэффициенты:\n",
      "-----------------------------------------------\n",
      "idiot                → 7.5512\n",
      "idea                 → 6.9608\n",
      "stupid               → 6.4062\n",
      "stupidity            → 6.1560\n",
      "more                 → 5.5381\n",
      "dumb                 → 4.8640\n",
      "party                → 4.7776\n",
      "crap                 → 4.5502\n",
      "damn                 → 4.2093\n",
      "liar                 → 4.1868\n"
     ]
    }
   ],
   "source": [
    "# Словарь: слово → индекс\n",
    "vocab = vectorizer.vocabulary_\n",
    "\n",
    "# Веса модели\n",
    "coefs = model.coef_[0]\n",
    "\n",
    "# Инвертируем: индекс → слово\n",
    "index_to_word = {idx: word for word, idx in vocab.items()}\n",
    "\n",
    "# Получаем индексы 10 слов с наибольшими весами\n",
    "top_indices = np.argsort(coefs)[-10:][::-1]\n",
    "\n",
    "# Преобразуем индексы в слова и веса\n",
    "top_words = [(index_to_word[i], coefs[i]) for i in top_indices]\n",
    "\n",
    "# Вывод\n",
    "print(\"10 самых «токсичных» слов и их коэффициенты:\")\n",
    "print(\"-----------------------------------------------\")\n",
    "for word, weight in top_words:\n",
    "    print(f\"{word:20s} → {weight:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c181c089",
   "metadata": {},
   "source": [
    "####  Задание 7 Взгляните на самые токсичные слова из задания 6. \n",
    "\n",
    "#### Вызывают ли у вас удивление какие-нибудь из них? \n",
    "\n",
    "#### Есть ли слова, которых, кажется, не должно быть в списке?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab458a86",
   "metadata": {},
   "source": [
    "Поскольку среди токсичных слов оказались сами по себе нетоксичные, это не значит, что модельработает неправильно. Скорее всего эти слова использовались в токсичном контексте. Для проверки я хочу вывечти 10 самых нетоксичных слов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345463e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 самых «нетоксичных» слов и их коэффициенты:\n",
      "--------------------------------------------------\n",
      "http                 → -1.0297\n",
      "than                 → -0.7726\n",
      "however              → -0.7256\n",
      "paying               → -0.5962\n",
      "example              → -0.5899\n",
      "agree                → -0.5722\n",
      "during               → -0.5518\n",
      "own                  → -0.5299\n",
      "question             → -0.5188\n",
      "isn                  → -0.5121\n"
     ]
    }
   ],
   "source": [
    "# 10 самых нетоксичных слов (наименьшие коэффициенты)\n",
    "bottom_indices = np.argsort(coefs)[:10]\n",
    "bottom_words = [(index_to_word[i], coefs[i]) for i in bottom_indices]\n",
    "\n",
    "print(\"10 самых «нетоксичных» слов и их коэффициенты:\")\n",
    "print(\"--------------------------------------------------\")\n",
    "for word, weight in bottom_words: # пара (слово, вес) внизу - самые нетоксичные\n",
    "    print(f\"{word:20s} → {weight:.4f}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "482c6a4e",
   "metadata": {},
   "source": [
    "Результат великолепен!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4724ac64",
   "metadata": {},
   "source": [
    "### Задание 8 Давайте попробуем протестировать модель на ее предвзятость, например, к религии."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0eba50d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Нормальное высказывание (вероятность: 0.41)\n",
      "Нормальное высказывание (вероятность: 0.41)\n",
      "Нормальное высказывание (вероятность: 0.34)\n",
      "Нормальное высказывание (вероятность: 0.43)\n"
     ]
    }
   ],
   "source": [
    "check_toxic(\"a christian friend\")\n",
    "check_toxic(\"muslimic culture\")\n",
    "check_toxic(\"my best friend is black\")\n",
    "check_toxic(\"white friend\")\n",
    "\n",
    "## Все высказывания отнесены к нормльным высказываениям. Можно сделать вывод о том, что у модели нет предвзятости."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "37a9b78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_bias(texts):\n",
    "    for t in texts:\n",
    "        vec = vectorizer.transform([t])\n",
    "        prob = model.predict_proba(vec)[0][1]\n",
    "        print(f\"{t:40s} → токсичность: {prob:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d21d5579",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have a christian friend                → токсичность: 0.41\n",
      "I have a muslim friend                   → токсичность: 0.41\n",
      "I have a white friend                    → токсичность: 0.42\n",
      "I have a black friend                    → токсичность: 0.42\n",
      "I have a Jewish friend                   → токсичность: 0.41\n",
      "I have an atheist friend                 → токсичность: 0.44\n",
      "I have a Hindu friend                    → токсичность: 0.41\n",
      "I have a Buddhist friend                 → токсичность: 0.41\n"
     ]
    }
   ],
   "source": [
    "samples = [\n",
    "    \"I have a christian friend\",\n",
    "    \"I have a muslim friend\",\n",
    "    \"I have a white friend\",\n",
    "    \"I have a black friend\",\n",
    "    \"I have a Jewish friend\",\n",
    "    \"I have an atheist friend\",\n",
    "    \"I have a Hindu friend\",\n",
    "    \"I have a Buddhist friend\",\n",
    "]\n",
    "\n",
    "check_bias(samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8061add0",
   "metadata": {},
   "source": [
    "#### Задание 9 Немного теории: \n",
    "#### в этике ИИ принято писать такой алгоритм, который будет соответствовать 4 критериям этики:\n",
    "\n",
    "В этике искусственного интеллекта особенно важны четыре ключевых принципа. Во-первых, это справедливость: алгоритмы не должны допускать дискриминации по таким признакам, как пол, раса, религия или возраст. Во-вторых, важна прозрачность — поведение модели должно быть объяснимым, чтобы пользователь мог понять, почему принято то или иное решение. Также необходима ответственность: должно быть ясно, кто отвечает за работу системы и как можно исправить возможные ошибки. И, наконец, надёжность — модель должна работать стабильно и предсказуемо в разных условиях."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23170f8",
   "metadata": {},
   "source": [
    "## Задание 10 Подумайте о том, как можно улучшить алгоритм, чтобы сделать его более этичным. Напишите 1–2 идеи.\n",
    "\n",
    "Чтобы сделать алгоритм более этичным, можно, во-первых, отфильтровать предвзятые или токсичные примеры из обучающих данных — особенно те, где нейтральные слова (например, «black», «muslim») часто встречаются в негативном контексте. \n",
    "\n",
    "Во-вторых, можно внедрить механизм корректировки весов признаков, снижающий влияние слов, не являющихся токсичными по смыслу, но часто встречающихся рядом с токсичными высказываниями. Это поможет уменьшить ложные срабатывания и повысить справедливость модели."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d0435a",
   "metadata": {},
   "source": [
    "Функция фильтрации слов с потенциальной предвзятостью"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7959205c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Список слов, которые не должны влиять на токсичность\n",
    "neutral_words = [\"black\", \"white\", \"muslim\", \"christian\", \"jewish\", \"hindu\", \"atheist\"]\n",
    "\n",
    "# Преобразуем в индексы из словаря векторизатора\n",
    "neutral_indices = [vectorizer.vocabulary_.get(word) for word in neutral_words]\n",
    "neutral_indices = [i for i in neutral_indices if i is not None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ddfe6dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обнуляем коэффициенты для \"чувствительных\" слов\n",
    "for idx in neutral_indices:\n",
    "    model.coef_[0][idx] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "22a0ebaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# постобработка вероятности\n",
    "def safe_vectorize(text):\n",
    "    tokens = text.lower().split()\n",
    "    filtered = [word for word in tokens if word not in neutral_words]\n",
    "    return vectorizer.transform([\" \".join(filtered)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "704d4ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = safe_vectorize(\"I have a black friend\")\n",
    "prob = model.predict_proba(vec)[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6464ed2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_toxic_safe(text):\n",
    "    vec = safe_vectorize(text)\n",
    "    prob = model.predict_proba(vec)[0][1]\n",
    "    \n",
    "    if prob >= 0.5:\n",
    "        print(f\"Токсично (без учёта чувствительных слов) → {prob:.2f}\")\n",
    "    else:\n",
    "        print(f\"Нормально (без учёта чувствительных слов) → {prob:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "610e9bcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Нормально (без учёта чувствительных слов) → 0.41\n",
      "Нормально (без учёта чувствительных слов) → 0.41\n",
      "Токсично (без учёта чувствительных слов) → 1.00\n",
      "Нормально (без учёта чувствительных слов) → 0.37\n"
     ]
    }
   ],
   "source": [
    "check_toxic_safe(\"I have a black friend\")\n",
    "check_toxic_safe(\"I have a muslim friend\")\n",
    "check_toxic_safe(\"You are stupid\")\n",
    "check_toxic_safe(\"You are a kind person\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451c95f7",
   "metadata": {},
   "source": [
    "Кстати, можно заметить, что степень токсичности в религиозных высказываниях не поменялась.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4a4f49",
   "metadata": {},
   "source": [
    "### Справочная информация (не имеет отношения к заданиям):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0e57ce",
   "metadata": {},
   "source": [
    "Для реализации этичного алгоритма на Python, соответствующего принципам справедливости, прозрачности, ответственности и надёжности, можно использовать специализированные библиотеки, такие как AI Fairness 360 (AIF360) от IBM или FAT Forensics. Эти инструменты помогают выявлять и устранять предвзятость в данных и моделях.\n",
    "arxiv.org\n",
    "\n",
    "Ниже приведён пример кода, демонстрирующий использование AIF360 для оценки и повышения справедливости модели логистической регрессии:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731e8e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Установка необходимых библиотек\n",
    "# !pip install aif360 scikit-learn pandas numpy\n",
    "\n",
    "# # Импорт библиотек\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from aif360.datasets import StandardDataset\n",
    "# from aif360.metrics import BinaryLabelDatasetMetric, ClassificationMetric\n",
    "# from aif360.algorithms.preprocessing import Reweighing\n",
    "\n",
    "# # Загрузка и подготовка данных\n",
    "# # Предположим, у нас есть DataFrame 'df' с признаками и целевой переменной 'label'\n",
    "# # Также определим чувствительный признак, например, 'gender'\n",
    "\n",
    "# # Преобразование данных в формат AIF360\n",
    "# dataset = StandardDataset(df,\n",
    "#                           label_name='label',\n",
    "#                           favorable_classes=[1],\n",
    "#                           protected_attribute_names=['gender'],\n",
    "#                           privileged_classes=[['male']])\n",
    "\n",
    "# # Разделение на обучающую и тестовую выборки\n",
    "# dataset_train, dataset_test = dataset.split([0.7], shuffle=True)\n",
    "\n",
    "# # Применение метода Reweighing для устранения предвзятости\n",
    "# RW = Reweighing(unprivileged_groups=[{'gender': 0}],\n",
    "#                 privileged_groups=[{'gender': 1}])\n",
    "# dataset_transf_train = RW.fit_transform(dataset_train)\n",
    "\n",
    "# # Обучение модели\n",
    "# X_train = dataset_transf_train.features\n",
    "# y_train = dataset_transf_train.labels.ravel()\n",
    "# sample_weight = dataset_transf_train.instance_weights\n",
    "\n",
    "# scaler = StandardScaler()\n",
    "# X_train = scaler.fit_transform(X_train)\n",
    "\n",
    "# model = LogisticRegression()\n",
    "# model.fit(X_train, y_train, sample_weight=sample_weight)\n",
    "\n",
    "# # Оценка модели\n",
    "# X_test = scaler.transform(dataset_test.features)\n",
    "# y_pred = model.predict(X_test)\n",
    "\n",
    "# # Преобразование предсказаний в формат AIF360\n",
    "# dataset_pred = dataset_test.copy()\n",
    "# dataset_pred.labels = y_pred\n",
    "\n",
    "# # Вычисление метрик справедливости\n",
    "# metric = ClassificationMetric(dataset_test, dataset_pred,\n",
    "#                               unprivileged_groups=[{'gender': 0}],\n",
    "#                               privileged_groups=[{'gender': 1}])\n",
    "\n",
    "# # Вывод разницы в точности между группами\n",
    "# print(\"Разница в точности между группами:\",\n",
    "#       metric.accuracy(privileged=True) - metric.accuracy(privileged=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2135fa85",
   "metadata": {},
   "source": [
    "В этом примере:\n",
    "\n",
    "Reweighing используется для перераспределения весов обучающих примеров, чтобы устранить предвзятость в данных.\n",
    "\n",
    "ClassificationMetric позволяет оценить справедливость модели по различным метрикам, таким как разница в точности между привилегированной и непривилегированной группами."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18df0158",
   "metadata": {},
   "source": [
    "Использование таких инструментов помогает разработчикам создавать более этичные и справедливые модели машинного обучения.\n",
    "\n",
    "Дополнительную информацию и примеры можно найти в официальной документации AIF360: https://aif360.readthedocs.io/en/latest/\n",
    "arxiv.org"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
